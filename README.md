# Analyzing GDRP Fines

Analyzing GDPR fines imposed by the European data protection authorities could reveal the main 
reasons and focus areas of the authorities for non-compliance and could allow our organization 
to timely address similar gaps in their data privacy strategy.


# Project Summary
On May 25, 2018, the European Union (EU) ‚ÄúGeneral Data Protection Regulation‚Äù (GDPR) became effective. The GDPR is a new data privacy initiative adopted by the EU to provide enhanced protection to EU citizens and their personal data. The penalties violations can result in up to twenty million euros or four percent of the company‚Äôs global annual revenue from the previous year, whichever number is higher. In addition, EU legislators impose fines for penalties to enforce data protection compliance.

## Objective
The purpose of the project is to analyze GDPR fines that have been issued since 2018 and to get: 

- **Basic insights regarding**:
  - Which industry sectors have been penalized the most?
  - Which individual companies have been penalized the most?
  - Which EU countries have the most violations?
  - Which GDPR articles have been violated the most?
  - What are the ‚Äúaverage costs‚Äù of a violation per sector?

- **Advanced insights** by correlating the GDPR fine dataset with the population by country (POP), gross domestic product (GDP), and corruption perception index (CPI) by country, the project intents to verify the following assumptions:
  - **A higher GDP** could lead to more reported cases, because a higher GDP could mean more companies in the country
  - **A higher CPI** could lead to more reported cases, because the public sector is maybe less influenced by the companies (higher CPI score = less corrupted)
  - **A higher population** could lead to more reported cases because more data subjects could execute their rights


# Project Organization

    ‚îú‚îÄ‚îÄ README.md          <- The top-level README for developers using this project.
    ‚îú‚îÄ‚îÄ data
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ external       <- Data from third party sources.
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ interim        <- Intermediate data that has been transformed.
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ processed      <- The final, canonical data sets for modeling.
    ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ raw            <- The original, immutable data dump.
    ‚îÇ
    ‚îú‚îÄ‚îÄ docs               <- A default Sphinx project; see sphinx-doc.org for details
    ‚îÇ
    ‚îú‚îÄ‚îÄ models             <- Trained and serialized models, model predictions, or model summaries
    ‚îÇ
    ‚îú‚îÄ‚îÄ notebooks          <- Jupyter notebooks. Naming convention is a number (for ordering),
    ‚îÇ                         the creator's initials, and a short `-` delimited description, e.g.
    ‚îÇ                         `01-data_load_and_cleaning`.
    ‚îÇ
    ‚îú‚îÄ‚îÄ references         <- Data dictionaries, manuals, and all other explanatory materials.
    ‚îÇ
    ‚îú‚îÄ‚îÄ reports            <- Generated analysis as HTML, PDF, LaTeX, etc.
    ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ figures        <- Generated graphics and figures to be used in reporting
    ‚îÇ
    ‚îú‚îÄ‚îÄ requirements.txt   <- The requirements file for reproducing the analysis environment, e.g.
    ‚îÇ                         generated, e.g., with `pip freeze > requirements.txt`


# Dataset
The project created, collectd, cleaned, manipulated and stored the datasets according to the following process flow:

![Process Flow](reports/figures/dataset_process_flow.png)

> ü§ù **Decisions**: 
> - For all datasets (tables), the same unique key is created and used: country+year.
> - All cleaned datasets will be stored in the SQLite file ‚Äúproject_GDPR-fines.sqlite‚Äù for the following reasons:
>    - Retain data types and structure (compared to xlsx or csv)
>    - Improve access outside of Python, e.g. via an SQLite DB Browser


**Legend**
- WS: Web scraping
- DCO: Data collection
- DCL: Data cleaning and manipulation

## Primary Dataset
### GDPR fines
The GDPR fines data is the primary dataset. The information is scraped from the GDPR Enforcement Tracker website and contains details about the imposed GDPR fines. 

The information is scrapped with the Selenium library, because the GDPR information is dynamically loaded via Javascript and not available as a text in the html source code. The parsing process was written by the project team and is documented in the notebook: ‚Äú01_DCO-WS_GDPR-Fines_enforcementtracker.ipynb‚Äù. 

| Column | dtype | atype | Rel. | Description |
|--------|-------|-------|------|-------------|
| ETid | str | O | No | Unique identifier assigned by the GDPR Enforcement Tracker |
| Country | str | N | Yes | Name of country |
| Date of Decision | str | O | Yes | Date when the fine was imposed |
| Fine [‚Ç¨] | int | Q | Yes | Amount of the fine in EUR |
| Controller/Processor | str | N | Yes | Data controller / processor / organization fined |
| Quoted Art. | str | N | Yes | Relevant GDPR article which was quoted for the imposed fine |
| Type | str | N | Yes | Reason/cause for the fine |
| Summary | str | N | Yes | Short explanation of the case |
| Authority | str | N | Yes | Name of the data protection authority who imposed the fine |
| Sector | str | N | Yes | Industry sector of the the controller/processor |


| Item | Source | Target |
|------|--------|--------|
| Access method | Web scraping (initial): Last scrap on 2021-11-28 | |
| Last update | | |
| Estimated size | | 926 records |
| No. of attributes | | 10 |
| Location | https://www.enforcementtracker.com/ | /data/external/ |
| Filename | Not applicable | gdpr_fines_enforcementtracker_p2.pkl |
| File format | HTML | Parsed: PKL |


> ‚ö†Ô∏è **Attention**: The initial parsing takes several hours, because for the detailed information (Summary, Authority and Sector) the page for every single case has to be opened and closed in sequence. The process also needs to be monitored due to potential timeout issues.

## Secondary Datasets
### Population
Countries of the world with their population over the years (1955 - 2020). The data is scraped from the Worldometer website. 234 out of 235 countries were parsed. Micronesia was excluded due to parsing issues. For the parsing the Beautiful Soup library is used. The parsing code was written by the project team and is documented in the notebook: ‚Äú01_DCO-WS_population_worldmeter.ipynb‚Äù.

| Column | dtype | atype | Rel. | Description |
|--------|-------|-------|------|-------------|
| Country | str | N | Yes | Name of the country |
| Year | int | O | Yes | Year of population |
| Population | int | Q | Yes | Amount of population |
| Yearly % Change | float | Q | No | Yearly change of the population |
| Urban Population | int | Q | No | Amount of urban population |


| Item | Source | Target |
|------|--------|--------|
| Access method | Web scraping (initial): Last scrap on 2021-11-28 | |
| Last update | N/A | |
| Estimated size | | 4212 (Micronesia excluded) |
| No. of attributes | | 5 |
| File location | https://www.worldometers.info/population/ | /data/external/ |
| Filename | Not applicable | population_by_country_p2.pkl |
| File format | HTML table | PKL |

> ü§ù **Decisions**: Micronesia was excluded due to parsing issues. Reasons for the parsing issues are related to the fact that Micronesia does not have all the data/columns compared to the other countries in the Worldmeter dataset. Considering that this country is not relevant for our analysis (no GDPR fines in Micronesia) the project team decided not to invest more time to cover this specific parsing case and decided to exclude the country.

### CPI Scores
The CPI dataset describes the Corruption Perceptions Index (CPI) per country. The CPI scores and ranks countries/territories based on how corrupt a country‚Äôs public sector is perceived to be. It is a composite index, a combination of surveys and assessments of corruption, collected by a variety of reputable institutions. 

The data is manually downloaded from the ‚ÄúTransparency International‚Äù website.

| Column | dtype | atype | Rel. | Description |
|--------|-------|-------|------|-------------|
| Country | str | N | Yes | Name of country |
| ISO3 | str | N | Yes | ISO code of the country name |
| CPI Score 20xx | int | Q | Yes | Corruption Perceptions Index (CPI) score of the year |

| Item | Source | Target |
|------|--------|--------|
| Access method | Download: Last download on 2021-11-29 | |
| Estimated size | 180 records | |
| No. of attributes | 34 | |
| File location | https://www.transparency.org/en/cpi/2020/index/ | /data/external/ |
| Filename | CPI2020_GlobalTablesTS_210125.xlsx | CPI2020_GlobalTablesTS_210125.xlsx |
| File format | XLSX | XLSX |

### GDP per capita
Gross Domestic Product (GDP) is the monetary value of all finished goods and services made within a country during a specific period. GDP provides an economic snapshot of a country, used to estimate the size of an economy and growth rate. 

This dataset contains the current GDP in USD, not corrected by the purchasing power parity (PPP) because we want to understand the overall amount of produced goods and services. The dataset is manually downloaded from the ‚ÄúThe World Bank‚Äù website.

| Column | dtype | atype | Rel. | Description |
|--------|-------|-------|------|-------------|
| Country Name | str | N | Yes | Name of country |
| Country Code | str | N | Yes | ISO code of the country name |
| Indicator Name | str | N | No | All fields contain 'GDP (current US$)' value |
| Indicator Code | str | N | No | All fields contains 'NY.GDP.MKTP.CD' value |
| Columns of years (1960-2020) | float | Q | Yes | The GDP value of the year |


| Item | Source | Target |
|------|--------|--------|
| Access method | Download: Last download on 2021-11-29 | |
| Estimated size | 266 records | |
| No. of attributes | 65 | |
| File location | https://data.worldbank.org/indicator/NY.GDP.MKTP.CD | /data/external/ |
| Filename | API_NY.GDP.MKTP.CD_DS2_en_excel_v2_3158925.xls | API_NY.GDP.MKTP.CD_DS2_en_excel_v2_3158925.xls |
| File format | XLS | XLS |

# Cleaning and Manipulation

**Joining Datasets**
The key attribute used to combine all datasets is the country name + year. Those attributes and values are present in all datasets.

**Main Challenges**
- Potential inconsistencies or spelling mistakes for the country naming 
- Missing values in the datasets
- Outliers in the datasets
- Breaking/melting ‚Äúyear columns‚Äù into rows

> ü§ù **Decision**: For cleaning or manipulation activities, an assert statement should be used to verify the expected outcome - where possible.


| Dataset | Processing Steps |
|---------|------------------|
| All datasets | ‚Ä¢ Lowercase column names<br>‚Ä¢ Check consistencies in categorical features<br>‚Ä¢ Create mapping table for country names + label encoding<br>‚Ä¢ Ensure consistent country names via mapping table<br>‚Ä¢ Create "key" column based on country+year for joining datasets<br>‚Ä¢ Encode categorical features<br>‚Ä¢ Drop unused columns<br>‚Ä¢ Check for missing values<br>‚Ä¢ Check for outliers |
| GDPR | ‚Ä¢ Lowercase column names<br>‚Ä¢ Clean and tokenize summary column for NLP analysis<br>‚Ä¢ Explode "quoted art." into separate columns<br>‚Ä¢ Label-encode: country, controller/processor, quoted art., sector, company, type<br>‚Ä¢ Extract year from date column<br>‚Ä¢ Create unique key column: country+year<br>‚Ä¢ Save result in SQLite DB-file |
| POP | ‚Ä¢ Lowercase column names<br>‚Ä¢ Calculate population 2021 based on average growth rate<br>‚Ä¢ Keep relevant columns: country, year<br>‚Ä¢ Label-encode country<br>‚Ä¢ Create unique key column: country+year<br>‚Ä¢ Create and assign percentile column<br>‚Ä¢ Keep only countries in GDPR-fine dataset<br>‚Ä¢ Save result in SQLite DB-file |
| CPI | ‚Ä¢ Skip first 2 rows during import<br>‚Ä¢ Lowercase column names<br>‚Ä¢ Calculate CPI score 2021 based on average growth rate<br>‚Ä¢ Keep relevant columns: country, CPI scores 2018-2021<br>‚Ä¢ Rename columns to years only<br>‚Ä¢ Melt 2018 to 2021 (single rows per year)<br>‚Ä¢ Clean/check country names for consistency<br>‚Ä¢ Keep only countries in GDPR-fine dataset<br>‚Ä¢ Label-encode country<br>‚Ä¢ Create unique key column: country+year<br>‚Ä¢ Create and assign percentile column<br>‚Ä¢ Save result in SQLite DB-file |
| GDP | ‚Ä¢ Skip first 3 rows during import<br>‚Ä¢ Lowercase column names<br>‚Ä¢ Calculate GDP 2021 based on average growth rate<br>‚Ä¢ Keep relevant columns: country name, 2018-2021<br>‚Ä¢ Melt 2018 to 2021 (single rows per year)<br>‚Ä¢ Clean/check country names for consistency<br>‚Ä¢ Keep only countries in GDPR-fine dataset<br>‚Ä¢ Label-encode country<br>‚Ä¢ Create unique key column: country+year<br>‚Ä¢ Create and assign percentile column<br>‚Ä¢ Save result in SQLite DB-file |

